{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"!pip install nltk\\nnltk.download('stopwords')\\nnltk.download('wordnet')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                               text\n",
       "1   ham  Go until jurong point, crazy.. Available only ...\n",
       "2   ham                      Ok lar... Joking wif u oni...\n",
       "3  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "4   ham  U dun say so early hor... U c already then say...\n",
       "5   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(\"SMSCollection.csv\",header = None, sep = ',')\n",
    "data.rename(columns={0: 'spam', 1: 'text'}, inplace=True)\n",
    "data = data.iloc[1:]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     752\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nostop</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                               text  \\\n",
       "1   ham  Go until jurong point, crazy.. Available only ...   \n",
       "2   ham                      Ok lar... Joking wif u oni...   \n",
       "3  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "4   ham  U dun say so early hor... U c already then say...   \n",
       "5   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "1  Go until jurong point crazy Available only in ...   \n",
       "2                            Ok lar Joking wif u oni   \n",
       "3  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "4        U dun say so early hor U c already then say   \n",
       "5  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "1  [go, until, jurong, point, crazy, available, o...   \n",
       "2                     [ok, lar, joking, wif, u, oni]   \n",
       "3  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "4  [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "5  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "\n",
       "                                              nostop  \\\n",
       "1  [go, jurong, point, crazy, available, bugis, n...   \n",
       "2                     [ok, lar, joking, wif, u, oni]   \n",
       "3  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "4      [u, dun, say, early, hor, u, c, already, say]   \n",
       "5  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "1  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "2                       [ok, lar, joke, wif, u, oni]   \n",
       "3  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "4      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "5  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                          lemmatized  \n",
       "1  [go, jurong, point, crazy, available, bugis, n...  \n",
       "2                     [ok, lar, joking, wif, u, oni]  \n",
       "3  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "4      [u, dun, say, early, hor, u, c, already, say]  \n",
       "5  [nah, dont, think, go, usf, life, around, though]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned'] = data['text'].apply(remove_punct)\n",
    "data['tokenized'] = data['cleaned'].apply(tokenize) \n",
    "data['nostop'] = data['tokenized'].apply(remove_stopwords)\n",
    "data['stemmed'] = data['nostop'].apply(stemming)\n",
    "data['lemmatized'] = data['nostop'].apply(lemmatizing)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nostop</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>FreeMsg Hey there darling its been 3 weeks now...</td>\n",
       "      <td>[freemsg, hey, there, darling, its, been, 3, w...</td>\n",
       "      <td>[freemsg, hey, darling, 3, weeks, word, back, ...</td>\n",
       "      <td>[freemsg, hey, darl, 3, week, word, back, id, ...</td>\n",
       "      <td>[freemsg, hey, darling, 3, week, word, back, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>As per your request Melle Melle Oru Minnaminun...</td>\n",
       "      <td>[as, per, your, request, melle, melle, oru, mi...</td>\n",
       "      <td>[per, request, melle, melle, oru, minnaminungi...</td>\n",
       "      <td>[per, request, mell, mell, oru, minnaminungint...</td>\n",
       "      <td>[per, request, melle, melle, oru, minnaminungi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>WINNER As a valued network customer you have b...</td>\n",
       "      <td>[winner, as, a, valued, network, customer, you...</td>\n",
       "      <td>[winner, valued, network, customer, selected, ...</td>\n",
       "      <td>[winner, valu, network, custom, select, receiv...</td>\n",
       "      <td>[winner, valued, network, customer, selected, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>Had your mobile 11 months or more U R entitled...</td>\n",
       "      <td>[had, your, mobile, 11, months, or, more, u, r...</td>\n",
       "      <td>[mobile, 11, months, u, r, entitled, update, l...</td>\n",
       "      <td>[mobil, 11, month, u, r, entitl, updat, latest...</td>\n",
       "      <td>[mobile, 11, month, u, r, entitled, update, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>Im gonna be home soon and i dont want to talk ...</td>\n",
       "      <td>[im, gonna, be, home, soon, and, i, dont, want...</td>\n",
       "      <td>[im, gonna, home, soon, dont, want, talk, stuf...</td>\n",
       "      <td>[im, gonna, home, soon, dont, want, talk, stuf...</td>\n",
       "      <td>[im, gonna, home, soon, dont, want, talk, stuf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>SIX chances to win CASH From 100 to 20000 poun...</td>\n",
       "      <td>[six, chances, to, win, cash, from, 100, to, 2...</td>\n",
       "      <td>[six, chances, win, cash, 100, 20000, pounds, ...</td>\n",
       "      <td>[six, chanc, win, cash, 100, 20000, pound, txt...</td>\n",
       "      <td>[six, chance, win, cash, 100, 20000, pound, tx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>URGENT You have won a 1 week FREE membership i...</td>\n",
       "      <td>[urgent, you, have, won, a, 1, week, free, mem...</td>\n",
       "      <td>[urgent, 1, week, free, membership, 100000, pr...</td>\n",
       "      <td>[urgent, 1, week, free, membership, 100000, pr...</td>\n",
       "      <td>[urgent, 1, week, free, membership, 100000, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words,...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "      <td>[ive, search, right, word, thank, breather, pr...</td>\n",
       "      <td>[ive, searching, right, word, thank, breather,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>XXXMobileMovieClub To use your credit click th...</td>\n",
       "      <td>[xxxmobilemovieclub, to, use, your, credit, cl...</td>\n",
       "      <td>[xxxmobilemovieclub, use, credit, click, wap, ...</td>\n",
       "      <td>[xxxmobilemovieclub, use, credit, click, wap, ...</td>\n",
       "      <td>[xxxmobilemovieclub, use, credit, click, wap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>Oh kim watching here</td>\n",
       "      <td>[oh, kim, watching, here]</td>\n",
       "      <td>[oh, kim, watching]</td>\n",
       "      <td>[oh, kim, watch]</td>\n",
       "      <td>[oh, kim, watching]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>Eh u remember how 2 spell his name Yes i did H...</td>\n",
       "      <td>[eh, u, remember, how, 2, spell, his, name, ye...</td>\n",
       "      <td>[eh, u, remember, 2, spell, name, yes, v, naug...</td>\n",
       "      <td>[eh, u, rememb, 2, spell, name, ye, v, naughti...</td>\n",
       "      <td>[eh, u, remember, 2, spell, name, yes, v, naug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "      <td>Fine if thats the way u feel Thats the way i...</td>\n",
       "      <td>[fine, if, that, s, the, way, u, feel, that, s...</td>\n",
       "      <td>[fine, way, u, feel, way, gota, b]</td>\n",
       "      <td>[fine, way, u, feel, way, gota, b]</td>\n",
       "      <td>[fine, way, u, feel, way, gota, b]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>England v Macedonia  dont miss the goalsteam n...</td>\n",
       "      <td>[england, v, macedonia, dont, miss, the, goals...</td>\n",
       "      <td>[england, v, macedonia, dont, miss, goalsteam,...</td>\n",
       "      <td>[england, v, macedonia, dont, miss, goalsteam,...</td>\n",
       "      <td>[england, v, macedonia, dont, miss, goalsteam,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spam                                               text  \\\n",
       "1      0  Go until jurong point, crazy.. Available only ...   \n",
       "2      0                      Ok lar... Joking wif u oni...   \n",
       "3      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "4      0  U dun say so early hor... U c already then say...   \n",
       "5      0  Nah I don't think he goes to usf, he lives aro...   \n",
       "6      1  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "7      0  Even my brother is not like to speak with me. ...   \n",
       "8      0  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "9      1  WINNER!! As a valued network customer you have...   \n",
       "10     1  Had your mobile 11 months or more? U R entitle...   \n",
       "11     0  I'm gonna be home soon and i don't want to tal...   \n",
       "12     1  SIX chances to win CASH! From 100 to 20,000 po...   \n",
       "13     1  URGENT! You have won a 1 week FREE membership ...   \n",
       "14     0  I've been searching for the right words to tha...   \n",
       "15     0                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "16     1  XXXMobileMovieClub: To use your credit, click ...   \n",
       "17     0                         Oh k...i'm watching here:)   \n",
       "18     0  Eh u remember how 2 spell his name... Yes i di...   \n",
       "19     0  Fine if thats the way u feel. Thats the way ...   \n",
       "20     1  England v Macedonia - dont miss the goals/team...   \n",
       "\n",
       "                                              cleaned  \\\n",
       "1   Go until jurong point crazy Available only in ...   \n",
       "2                             Ok lar Joking wif u oni   \n",
       "3   Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "4         U dun say so early hor U c already then say   \n",
       "5   Nah I dont think he goes to usf he lives aroun...   \n",
       "6   FreeMsg Hey there darling its been 3 weeks now...   \n",
       "7   Even my brother is not like to speak with me T...   \n",
       "8   As per your request Melle Melle Oru Minnaminun...   \n",
       "9   WINNER As a valued network customer you have b...   \n",
       "10  Had your mobile 11 months or more U R entitled...   \n",
       "11  Im gonna be home soon and i dont want to talk ...   \n",
       "12  SIX chances to win CASH From 100 to 20000 poun...   \n",
       "13  URGENT You have won a 1 week FREE membership i...   \n",
       "14  Ive been searching for the right words to than...   \n",
       "15                  I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "16  XXXMobileMovieClub To use your credit click th...   \n",
       "17                               Oh kim watching here   \n",
       "18  Eh u remember how 2 spell his name Yes i did H...   \n",
       "19  Fine if thats the way u feel Thats the way i...   \n",
       "20  England v Macedonia  dont miss the goalsteam n...   \n",
       "\n",
       "                                            tokenized  \\\n",
       "1   [go, until, jurong, point, crazy, available, o...   \n",
       "2                      [ok, lar, joking, wif, u, oni]   \n",
       "3   [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "4   [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "5   [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "6   [freemsg, hey, there, darling, its, been, 3, w...   \n",
       "7   [even, my, brother, is, not, like, to, speak, ...   \n",
       "8   [as, per, your, request, melle, melle, oru, mi...   \n",
       "9   [winner, as, a, valued, network, customer, you...   \n",
       "10  [had, your, mobile, 11, months, or, more, u, r...   \n",
       "11  [im, gonna, be, home, soon, and, i, dont, want...   \n",
       "12  [six, chances, to, win, cash, from, 100, to, 2...   \n",
       "13  [urgent, you, have, won, a, 1, week, free, mem...   \n",
       "14  [ive, been, searching, for, the, right, words,...   \n",
       "15         [i, have, a, date, on, sunday, with, will]   \n",
       "16  [xxxmobilemovieclub, to, use, your, credit, cl...   \n",
       "17                          [oh, kim, watching, here]   \n",
       "18  [eh, u, remember, how, 2, spell, his, name, ye...   \n",
       "19  [fine, if, that, s, the, way, u, feel, that, s...   \n",
       "20  [england, v, macedonia, dont, miss, the, goals...   \n",
       "\n",
       "                                               nostop  \\\n",
       "1   [go, jurong, point, crazy, available, bugis, n...   \n",
       "2                      [ok, lar, joking, wif, u, oni]   \n",
       "3   [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "4       [u, dun, say, early, hor, u, c, already, say]   \n",
       "5   [nah, dont, think, goes, usf, lives, around, t...   \n",
       "6   [freemsg, hey, darling, 3, weeks, word, back, ...   \n",
       "7   [even, brother, like, speak, treat, like, aids...   \n",
       "8   [per, request, melle, melle, oru, minnaminungi...   \n",
       "9   [winner, valued, network, customer, selected, ...   \n",
       "10  [mobile, 11, months, u, r, entitled, update, l...   \n",
       "11  [im, gonna, home, soon, dont, want, talk, stuf...   \n",
       "12  [six, chances, win, cash, 100, 20000, pounds, ...   \n",
       "13  [urgent, 1, week, free, membership, 100000, pr...   \n",
       "14  [ive, searching, right, words, thank, breather...   \n",
       "15                                     [date, sunday]   \n",
       "16  [xxxmobilemovieclub, use, credit, click, wap, ...   \n",
       "17                                [oh, kim, watching]   \n",
       "18  [eh, u, remember, 2, spell, name, yes, v, naug...   \n",
       "19                 [fine, way, u, feel, way, gota, b]   \n",
       "20  [england, v, macedonia, dont, miss, goalsteam,...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "1   [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "2                        [ok, lar, joke, wif, u, oni]   \n",
       "3   [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "4       [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "5   [nah, dont, think, goe, usf, live, around, tho...   \n",
       "6   [freemsg, hey, darl, 3, week, word, back, id, ...   \n",
       "7   [even, brother, like, speak, treat, like, aid,...   \n",
       "8   [per, request, mell, mell, oru, minnaminungint...   \n",
       "9   [winner, valu, network, custom, select, receiv...   \n",
       "10  [mobil, 11, month, u, r, entitl, updat, latest...   \n",
       "11  [im, gonna, home, soon, dont, want, talk, stuf...   \n",
       "12  [six, chanc, win, cash, 100, 20000, pound, txt...   \n",
       "13  [urgent, 1, week, free, membership, 100000, pr...   \n",
       "14  [ive, search, right, word, thank, breather, pr...   \n",
       "15                                     [date, sunday]   \n",
       "16  [xxxmobilemovieclub, use, credit, click, wap, ...   \n",
       "17                                   [oh, kim, watch]   \n",
       "18  [eh, u, rememb, 2, spell, name, ye, v, naughti...   \n",
       "19                 [fine, way, u, feel, way, gota, b]   \n",
       "20  [england, v, macedonia, dont, miss, goalsteam,...   \n",
       "\n",
       "                                           lemmatized  \n",
       "1   [go, jurong, point, crazy, available, bugis, n...  \n",
       "2                      [ok, lar, joking, wif, u, oni]  \n",
       "3   [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "4       [u, dun, say, early, hor, u, c, already, say]  \n",
       "5   [nah, dont, think, go, usf, life, around, though]  \n",
       "6   [freemsg, hey, darling, 3, week, word, back, i...  \n",
       "7   [even, brother, like, speak, treat, like, aid,...  \n",
       "8   [per, request, melle, melle, oru, minnaminungi...  \n",
       "9   [winner, valued, network, customer, selected, ...  \n",
       "10  [mobile, 11, month, u, r, entitled, update, la...  \n",
       "11  [im, gonna, home, soon, dont, want, talk, stuf...  \n",
       "12  [six, chance, win, cash, 100, 20000, pound, tx...  \n",
       "13  [urgent, 1, week, free, membership, 100000, pr...  \n",
       "14  [ive, searching, right, word, thank, breather,...  \n",
       "15                                     [date, sunday]  \n",
       "16  [xxxmobilemovieclub, use, credit, click, wap, ...  \n",
       "17                                [oh, kim, watching]  \n",
       "18  [eh, u, remember, 2, spell, name, yes, v, naug...  \n",
       "19                 [fine, way, u, feel, way, gota, b]  \n",
       "20  [england, v, macedonia, dont, miss, goalsteam,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['spam'] = np.where(data['spam'] == 'ham', 0, 1) #where 0 is ham and 1 is spam\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('spam', axis=1), data['spam'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>020603</th>\n",
       "      <th>0207</th>\n",
       "      <th>02070836089</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zed</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6740 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  008704050406  01223585236  01223585334   02  020603  0207  \\\n",
       "0  0.000000  0.0           0.0          0.0          0.0  0.0     0.0   0.0   \n",
       "1  0.000000  0.0           0.0          0.0          0.0  0.0     0.0   0.0   \n",
       "2  0.000000  0.0           0.0          0.0          0.0  0.0     0.0   0.0   \n",
       "3  0.000000  0.0           0.0          0.0          0.0  0.0     0.0   0.0   \n",
       "4  0.139735  0.0           0.0          0.0          0.0  0.0     0.0   0.0   \n",
       "\n",
       "   02070836089  02072069400  ...  zed  zero  zhong  zindgi  zoe  zouk  zyada  \\\n",
       "0          0.0          0.0  ...  0.0   0.0    0.0     0.0  0.0   0.0    0.0   \n",
       "1          0.0          0.0  ...  0.0   0.0    0.0     0.0  0.0   0.0    0.0   \n",
       "2          0.0          0.0  ...  0.0   0.0    0.0     0.0  0.0   0.0    0.0   \n",
       "3          0.0          0.0  ...  0.0   0.0    0.0     0.0  0.0   0.0    0.0   \n",
       "4          0.0          0.0  ...  0.0   0.0    0.0     0.0  0.0   0.0    0.0   \n",
       "\n",
       "     ü  üll  〨ud  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 6740 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "vectorizer = tfidf_vect.fit(X_train['text'])\n",
    "\n",
    "tfidf_train = vectorizer.transform(X_train['text'])\n",
    "X_train_vect =  pd.DataFrame(tfidf_train.toarray(), columns = vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_test = vectorizer.transform(X_test['text'])\n",
    "X_test_vect =  pd.DataFrame(tfidf_test.toarray(), columns = vectorizer.get_feature_names())\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Baseline Model's accuracy on train data is 86.11%.\n",
      "The Naive Baseline Model's accuracy on test data is 87.46%.\n"
     ]
    }
   ],
   "source": [
    "modal_class_label = stats.mode(y_train)[0]\n",
    "y_train_preds_naive = [int(modal_class_label) for row in X_train.iloc[:,0]]\n",
    "y_test_preds_naive = [int(modal_class_label) for row in X_test.iloc[:,0]]\n",
    "\n",
    "# train accuracy score\n",
    "y_true = y_train\n",
    "y_pred = y_train_preds_naive\n",
    "\n",
    "train_accuracy_naive = accuracy_score(y_true, y_pred) * 100\n",
    "print(f\"The Naive Baseline Model's accuracy on train data is {train_accuracy_naive:.2f}%.\")\n",
    "\n",
    "# test accuracy score\n",
    "y_true = y_test\n",
    "y_pred = y_test_preds_naive\n",
    "\n",
    "test_accuracy_naive = accuracy_score(y_true, y_pred) * 100\n",
    "print(f\"The Naive Baseline Model's accuracy on test data is {test_accuracy_naive:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RandomForestClassifier's accuracy on train data is 100.00%.\n",
      "The RandomForestClassifier's accuracy on test data is 97.73%.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "\n",
    "#test accuracy score\n",
    "y_true = y_train\n",
    "y_pred = rf_model.predict(X_train_vect)\n",
    "\n",
    "train_accuracy_ranfor = accuracy_score(y_true, y_pred) * 100\n",
    "print(f\"The RandomForestClassifier's accuracy on train data is {train_accuracy_ranfor:.2f}%.\")\n",
    "\n",
    "#test accuracy score\n",
    "y_true = y_test\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "\n",
    "test_accuracy_ranfor = accuracy_score(y_true, y_pred) * 100\n",
    "print(f\"The RandomForestClassifier's accuracy on test data is {test_accuracy_ranfor:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Prediction Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#logreg = LogisticRegression(solver='liblinear')\n",
    "#logreg.fit(X_train_vect, y_train)\n",
    "#y_train_preds_logreg = logreg.predict(X_train_vect)\n",
    "#y_test_preds_logreg = logreg.predict(X_test_vect)\n",
    "\n",
    "# train accuracy score\n",
    "#y_true = y_train\n",
    "#y_pred = y_train_preds_logreg\n",
    "\n",
    "#train_accuracy_logreg = accuracy_score(y_true, y_pred) * 100\n",
    "#print(f\"The LogReg Model's accuracy on train data is {train_accuracy_logreg:.2f}%.\")\n",
    "\n",
    "# test accuracy score\n",
    "#y_true = y_test\n",
    "#y_pred = y_test_preds_logreg\n",
    "\n",
    "#test_accuracy_logreg = accuracy_score(y_true, y_pred) * 100\n",
    "#print(f\"The LogReg Model's accuracy on test data is {test_accuracy_logreg:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#dtree = DecisionTreeClassifier(random_state=0)\n",
    "#dtree.fit(X_train_vect, y_train)\n",
    "#y_train_preds_dtree = dtree.predict(X_train_vect)\n",
    "#y_test_preds_dtree = dtree.predict(X_test_vect)\n",
    "\n",
    "# train accuracy score\n",
    "#y_true = y_train\n",
    "#y_pred = y_train_preds_dtree\n",
    "\n",
    "#train_accuracy_dtree = accuracy_score(y_true, y_pred) * 100\n",
    "#print(f\"The DTree Model's accuracy on train data is {train_accuracy_dtree:.2f}%.\")\n",
    "\n",
    "# test accuracy score\n",
    "#y_true = y_test\n",
    "#y_pred = y_test_preds_dtree\n",
    "\n",
    "#test_accuracy_dtree = accuracy_score(y_true, y_pred) * 100\n",
    "#print(f\"The DTRee Model's accuracy on test data is {test_accuracy_dtree:.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of different predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text): #where 0 is ham and 1 is spam\n",
    "    test = [[text]]\n",
    "    df = pd.DataFrame(test, columns = ['text'])\n",
    "    df_test = vectorizer.transform(df['text'])\n",
    "    array_test = pd.DataFrame(df_test.toarray())\n",
    "    y_pred = rf_model.predict(array_test)\n",
    "    \n",
    "    if(y_pred[0] == 1): #where 0 is ham and 1 is spam\n",
    "        print(\"Message Type: \" + \"spam\" )\n",
    "    \n",
    "    elif(y_pred[0] == 0): #where 0 is ham and 1 is spam\n",
    "        print(\"Message Type: \" + \"ham\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Type: ham\n"
     ]
    }
   ],
   "source": [
    "predict(\"hello hello u wan come over to my hse tmr?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Type: spam\n"
     ]
    }
   ],
   "source": [
    "predict(\"free entry chance win urgent next week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Type: ham\n"
     ]
    }
   ],
   "source": [
    "predict(\"Dear client, your Trading Account has been successfully opened. Please visit www.tigerbrokers.com.sg, select My Account and complete Deposit Notification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Type: spam\n"
     ]
    }
   ],
   "source": [
    "predict(\"Top Up 100% bonus $50 free $50 DOUBLE BONUS FOR NEW MEMBERS UP TO 300 SGD FOR CASING SP0RT,H0URSE,l0TTERY Register Now Free Spin www.ads4u.asia/l/3l4p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Type: ham\n"
     ]
    }
   ],
   "source": [
    "predict(\"Hey bro/sis, looking for betting account? -Soccer -Casion&Slots -HorseRace 0 deposit! 10-30% bonus/rebate!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Type: spam\n"
     ]
    }
   ],
   "source": [
    "predict(\"WoW Power lah Credit Acc -NO NEED DEPOSIT -REBATE 10% Cash Acc -Welcome Bonus 50% >LiveC@sino >Sl0t > SPORT wa.me/+6581524963 GOOD AND FAST SERVICE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Type: spam\n"
     ]
    }
   ],
   "source": [
    "predict(\"Afternoon I'm Abby from SG. Do you like traveling? I got some good opportunity to get some passive income jb introduce to you. If you are interested just simplty reply me yes and i will send you more detail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Type: spam\n"
     ]
    }
   ],
   "source": [
    "predict(\"Hello do you free and easy passive income? I have a job for you with very little work, reply to me for more detail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of deleting telegram chat upon scam message detection with use of telethon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.tl.functions.messages import DeleteChatUserRequest\n",
    "\n",
    "def deleteChat(text):\n",
    "    if(predict(text)==1):\n",
    "        with TelegramClient('name', api_id, api_hash) as client:\n",
    "            client(functions.messages.DeleteChatUserRequest(\n",
    "            chat_id=chat_id,\n",
    "            user_id='me'))\n",
    "\n",
    "            client.run_until_disconnected()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
